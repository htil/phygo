{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Study.__init__() got an unexpected keyword argument 'setup_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 190\u001b[39m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, plot_epochs=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    188\u001b[39m         \u001b[38;5;28mself\u001b[39m.run_study(\u001b[38;5;28mself\u001b[39m.csv_file, \u001b[38;5;28mself\u001b[39m.event_file, plot_epochs)\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m study = \u001b[43mStudy\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/study5_data.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mevents/study5.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mevents/study5_event_labels.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msetup_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meeg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m study.run()\n\u001b[32m    192\u001b[39m study.get_pca()\n",
      "\u001b[31mTypeError\u001b[39m: Study.__init__() got an unexpected keyword argument 'setup_type'"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from brainflow.board_shim import BoardShim, BoardIds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from brainflow.data_filter import DataFilter, FilterTypes, AggOperations\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "# Disable MNE logging output\n",
    "mne.set_log_level('ERROR')\n",
    "\n",
    "class Study:\n",
    "    def __init__(self, csv_file, event_file, event_labels_file, sfreq=200):\n",
    "        self.csv_file = csv_file\n",
    "        self.event_file = event_file\n",
    "        # self.event_dict = event_dict\n",
    "        self.dataset_x = list()\n",
    "        self.dataset_y = list()\n",
    "        self.sfreq = sfreq\n",
    "        self.raw = None\n",
    "        self.filtered = None\n",
    "        self.epochs_filtered = None\n",
    "        self.events = None\n",
    "        self.lda = None\n",
    "        self.event_labels_file = event_labels_file\n",
    "\n",
    "    \n",
    "    def get_lda(self, n_components=2, colors=['red', 'green', 'blue', 'purple']):\n",
    "        # Apply LDA to reduce to 2D\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        X_lda = lda.fit_transform(self.dataset_x, self.dataset_y)\n",
    "\n",
    "        # Create index array based on length of labels\n",
    "        indices = np.arange(len(self.event_labels))\n",
    "\n",
    "        # Plot the reduced data\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for color, i, label in zip(colors, indices, self.event_labels):\n",
    "            plt.scatter(X_lda[self.dataset_y == i, 0], X_lda[self.dataset_y == i, 1], alpha=0.7, color=color, label=label, edgecolor='k')\n",
    "\n",
    "        plt.title('LDA: Dimensionality Reduction (2D)')\n",
    "        plt.xlabel('LD1')\n",
    "        plt.ylabel('LD2')\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def filter_data(self, raw, l_freq=1.0, h_freq=95.0):\n",
    "        filtered = raw.copy().filter(l_freq=l_freq, h_freq=h_freq)\n",
    "        self.filtered = filtered.notch_filter(freqs=60)\n",
    "        return filtered\n",
    "\n",
    "    def load_events(self, file_path):\n",
    "        events = np.loadtxt(file_path, delimiter=',', dtype=int)\n",
    "        return events\n",
    "    \n",
    "    def raw_to_epochs(self,raw, event_file, event_dict, tmin=-0.1, tmax=2.0, baseline=None, reject=None):\n",
    "        events = np.array(self.load_events(event_file))  \n",
    "        epochs = mne.Epochs(raw, events, event_id=event_dict, tmin=tmin, tmax=tmax, preload=True, baseline=baseline, reject=reject)\n",
    "        # psd = epochs.compute_psd()\n",
    "        return epochs, events\n",
    "\n",
    "    def csv_to_dataframe(self, file):\n",
    "        eeg_channels_names = [str(i) for i in range(15)]\n",
    "        df = pd.read_csv(file, usecols = eeg_channels_names).transpose()\n",
    "        return df\n",
    "\n",
    "    def df_to_raw( self, df, sfreq=200, ch_types='emg'):\n",
    "        # eeg_channels_names = BoardShim.get_eeg_names(self.board_id)\n",
    "        eeg_channels_names = [str(i) for i in range(df.shape[0])]\n",
    "        ch_types = ['eeg'] * len(eeg_channels_names)\n",
    "\n",
    "        # Create MNE info object\n",
    "        info = mne.create_info(ch_names = eeg_channels_names, sfreq = sfreq, ch_types=ch_types)\n",
    "\n",
    "        # Create MNE raw object\n",
    "        raw = mne.io.RawArray(df, info)\n",
    "        raw.load_data()\n",
    "        # raw.plot(clipping=None, scalings=dict(eeg='1e3', emg='1e5'))\n",
    "\n",
    "        return raw\n",
    "\n",
    "    def csv_to_raw(self, file, start_channel=0, end_channel=15):\n",
    "        df = self.csv_to_dataframe(file)\n",
    "        df = df.iloc[start_channel:end_channel, :]\n",
    "        raw = self.df_to_raw(df)\n",
    "        return raw\n",
    "\n",
    "    def get_band_powers(self, epoch):\n",
    "        # Currently using featiures in 10hz bins inspired by: \n",
    "        # Saponas, T. S., Tan, D. S., Morris, D. & Balakrishnan, R. Demonstrating the feasibility of using forearm electromyography for muscle-computer interfaces. 515â€“524 (2008) doi:10.1145/1357054.1357138.\n",
    "\n",
    "        # [avgs, stddevs] = DataFilter.get_custom_band_powers(epoch, [(1,10), (10, 20), (20, 30), (30, 40), (40, 50), (50, 60), (60, 70), (70, 80), (80, 90)], [0], self.sfreq, False)\n",
    "        [avgs, stddevs] = DataFilter.get_custom_band_powers(epoch, [(1,10), (10, 20), (20, 30), (30, 40), (40, 50), (50, 60), (60, 70), (70, 80), (80, 90)], [0], self.sfreq, False)\n",
    "        # rel_avg = [avgs[0] / avgs[8] * 1000, avgs[1] / avgs[7] * 1000, avgs[3] / avgs[6] * 1000, avgs[4] / avgs[5] * 1000]\n",
    "        return avgs\n",
    "\n",
    "    def get_band_power_by_epoch(self, epochs, epoch_index):\n",
    "        selected_epoch = epochs[epoch_index, :, :].reshape(1, -1)\n",
    "        avgs = self.get_band_powers(selected_epoch)\n",
    "        return avgs\n",
    "\n",
    "    def add_data_and_labels(self, epochs, event_id, label):\n",
    "        epochs_data = epochs[event_id].get_data()\n",
    "        for i in range(epochs_data.shape[0]):\n",
    "            avgs = self.get_band_power_by_epoch(epochs_data, i)\n",
    "            self.dataset_x.append(avgs)\n",
    "            self.dataset_y.append(label)\n",
    "\n",
    "    def plot_band_powers(self, avgs, title=\"Average Band Powers\"):\n",
    "        # Create bar plot of average band powers\n",
    "        plt.figure(figsize=(10,6))\n",
    "        bands = ['(1-10Hz)', '(10-20Hz)', '(20-30Hz)', '(40-50Hz)', \n",
    "                '(50-60Hz)', '(70-80Hz)', '(80-90Hz)']\n",
    "        plt.bar(bands, avgs)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.ylabel('Power')\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def get_pca(self, n_components=2, colors=['red', 'green', 'blue', 'purple']):\n",
    "        print(\"get_pca\")\n",
    "        # Apply PCA to reduce dimensionality\n",
    "        pca = PCA(n_components=n_components)\n",
    "        \n",
    "        print(self.dataset_x)\n",
    "        print(self.dataset_y)\n",
    "        X_pca = pca.fit_transform(self.dataset_x)\n",
    "\n",
    "        # Create index array based on length of labels\n",
    "        indices = np.arange(len(self.event_labels))\n",
    "\n",
    "        # Plot the reduced data\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for color, i, label in zip(colors, indices, self.event_labels):\n",
    "            plt.scatter(X_pca[self.dataset_y == i, 0], X_pca[self.dataset_y == i, 1], alpha=0.7, color=color, label=label, edgecolor='k')\n",
    "\n",
    "        plt.title('PCA: Dimensionality Reduction (2D)')\n",
    "        plt.xlabel('PC1')\n",
    "        plt.ylabel('PC2')\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_tfr(self, epochs, event):\n",
    "        # Time frequency analysis\n",
    "        fmax = 100\n",
    "        freqs = np.logspace(*np.log10([1, fmax]), num=fmax)\n",
    "        n_cycles = freqs / 2.0\n",
    "        baseline = (-0.1, 0)\n",
    "\n",
    "        epochs_tfr_relax = epochs[event].compute_tfr(\"morlet\", n_cycles=n_cycles, return_itc=False, freqs=freqs, average=True, use_fft=True)\n",
    "        epochs_tfr_relax.plot(title=event, baseline=baseline, mode=\"logratio\") # vmax=1e-8,\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    def run_study(self, csv_file, event_file, plot_epochs=False):\n",
    "        self.raw = self.csv_to_raw(csv_file, 1, 2)\n",
    "        self.filtered = self.filter_data(self.raw)\n",
    "        self.event_labels =  np.loadtxt(self.event_labels_file, delimiter=',', dtype=str)\n",
    "        print(self.event_labels)\n",
    "        self.event_dict = {str(label): i for i, label in enumerate(self.event_labels)}\n",
    "\n",
    "        epochs_filtered, events = self.raw_to_epochs(self.filtered, event_file, self.event_dict, tmin=0.0, tmax=2.0)\n",
    "        self.epochs_filtered = epochs_filtered\n",
    "        if plot_epochs:\n",
    "            print(\"Plotting epochs\")\n",
    "            self.epochs_filtered.plot(scalings=dict(eeg='1e3', emg='1e5'), events=events)\n",
    "\n",
    "        self.events = events\n",
    "\n",
    "        for event_name, event_id in self.event_dict.items():\n",
    "            self.add_data_and_labels(self.epochs_filtered, event_name, event_id)\n",
    "\n",
    "        self.dataset_x = np.array(self.dataset_x)\n",
    "        self.dataset_y = np.array(self.dataset_y)\n",
    "\n",
    "        for event in self.event_labels:\n",
    "            self.plot_tfr(self.epochs_filtered, event)\n",
    "\n",
    "    def run(self, plot_epochs=False):\n",
    "        self.run_study(self.csv_file, self.event_file, plot_epochs)\n",
    "\n",
    "study = Study(\"data/study5_data.csv\", \"events/study5.txt\", \"events/study5_event_labels.txt\")\n",
    "study.run()\n",
    "study.get_pca()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
